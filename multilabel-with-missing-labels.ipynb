{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: /Users/hobs/code/Multitask_Learning_Keras\n",
      "DATA_FILEPATH: /Users/hobs/code/Multitask_Learning_Keras/data/dataset.h5\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Convolution2D, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "if not 'workbookDir' in globals():\n",
    "    BASE_DIR = os.path.abspath(os.getcwd())\n",
    "print('BASE_DIR: ' + BASE_DIR)\n",
    "os.chdir(BASE_DIR)  # If you changed the current working dir, this will take you back to the workbook dir.\n",
    "\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "DATA_FILEPATH = os.path.join(DATA_DIR, 'dataset.h5')\n",
    "MODEL_FILEPATH = os.path.join(DATA_DIR, 'multitask_model.h5')\n",
    "print('DATA_FILEPATH: ' + DATA_FILEPATH)\n",
    "assert(os.path.isfile(DATA_FILEPATH))\n",
    "\n",
    "def load():\n",
    "    f = h5py.File(os.path.join(BASE_DIR, 'data', 'dataset.h5'))\n",
    "    x = f['x'].value\n",
    "    y = f['y'].value\n",
    "    f.close()\n",
    "    x_train , x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=100)\n",
    "    x_train = np.rollaxis(x_train, 1, 4)\n",
    "    x_test = np.rollaxis(x_test, 1, 4)\n",
    "    x_train = x_train  / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING_LABEL_FLAG = -1\n",
    "MISSING_LABEL_PROB = 0\n",
    "\n",
    "y_train_missing = np.random.rand(*y_train.shape) < MISSING_LABEL_PROB\n",
    "y_train[y_train_missing] = MISSING_LABEL_FLAG\n",
    "\n",
    "def multitask_accuracy(y_true, y_pred):\n",
    "    # https://github.com/keras-team/keras/issues/3893#issuecomment-258037118\n",
    "    dtype = K.floatx()\n",
    "    total = K.sum(K.cast(K.not_equal(y_true, MISSING_LABEL_FLAG), dtype))\n",
    "    correct = K.sum(K.cast(K.equal(y_true, K.round(y_pred)), dtype))\n",
    "    return K.cast(correct / total, dtype)\n",
    "\n",
    "def multitask_loss(y_true, y_pred):\n",
    "    dtype = K.floatx()\n",
    "    return K.cast(1., dtype) - multitask_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bfc037876f63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    508\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    510\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    511\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             raise ValueError('An operation has `None` for gradient. '\n\u001b[0m\u001b[1;32m     92\u001b[0m                              \u001b[0;34m'Please make sure that all of your ops have a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                              \u001b[0;34m'gradient defined (i.e. are differentiable). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval."
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "num_classes = 5\n",
    "epochs = 4\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 100, 100\n",
    "channels = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding='same',input_shape=(img_rows, img_cols, channels)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "## This is what Francois suggests for merging model outputs and using an mask on the input\n",
    "## https://github.com/keras-team/keras/issues/3206#issuecomment-232446030\n",
    "## uses the functional Keras API:\n",
    "# from keras.layers import Masking, Merge\n",
    "# Merge([network_outputs, Masking(mask_value=MISSING_LABEL_FLAG)(mask_input)], mode=lambda xs: xs[0], output_mask=lambda xs: xs[1])\n",
    "\n",
    "\n",
    "model.compile(loss=multitask_loss,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = np.array(['desert', 'mountain', 'sea', 'sunset', 'trees'])\n",
    "\n",
    "def infer(input_data, model=model):\n",
    "    labels = []\n",
    "    y_pred = model.predict(input_data)\n",
    "    \n",
    "    # Performing masking\n",
    "    y_pred = (y_pred > 0.5) * 1.0\n",
    "    \n",
    "    for i in range(y_pred.shape[0]):\n",
    "        # select the indices\n",
    "        indices = np.where(y_pred[i] == 1.0)[0]\n",
    "        # Adding the results \n",
    "        labels.append(CLASSES[indices].tolist())\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_FILEPATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d2f0e6f97f9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_FILEPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'MODEL_FILEPATH' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sea'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " ['desert', 'mountain'],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " ['mountain'],\n",
       " [],\n",
       " ['sea'],\n",
       " ['trees'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " ['trees'],\n",
       " ['sunset'],\n",
       " ['sea'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['trees'],\n",
       " [],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['sea'],\n",
       " [],\n",
       " [],\n",
       " ['trees'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " ['trees'],\n",
       " ['trees'],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " ['mountain'],\n",
       " ['mountain'],\n",
       " ['mountain'],\n",
       " ['sea'],\n",
       " [],\n",
       " [],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['mountain'],\n",
       " ['sea'],\n",
       " ['mountain', 'trees'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['mountain'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['mountain'],\n",
       " ['trees'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['sunset'],\n",
       " ['sea'],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['mountain'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['desert'],\n",
       " ['desert', 'sunset'],\n",
       " ['trees'],\n",
       " [],\n",
       " [],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['sunset'],\n",
       " ['sea'],\n",
       " ['mountain'],\n",
       " ['trees'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['sunset'],\n",
       " ['mountain'],\n",
       " ['sea'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['trees'],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['sea'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['sunset'],\n",
       " ['trees'],\n",
       " ['desert'],\n",
       " ['mountain'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " ['sea'],\n",
       " ['sunset'],\n",
       " ['mountain', 'trees'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['sea'],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['sunset'],\n",
       " [],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " [],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " ['trees'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['sea'],\n",
       " ['sea'],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['desert', 'sunset'],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['trees'],\n",
       " ['sunset'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['sea'],\n",
       " ['mountain'],\n",
       " ['sunset'],\n",
       " ['trees'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " ['sea'],\n",
       " ['desert'],\n",
       " ['mountain'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " ['sea', 'sunset'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " ['sunset'],\n",
       " [],\n",
       " ['sea'],\n",
       " ['mountain'],\n",
       " [],\n",
       " ['sunset'],\n",
       " ['mountain', 'trees'],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['sea'],\n",
       " ['mountain'],\n",
       " ['mountain'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['trees'],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['mountain'],\n",
       " ['trees'],\n",
       " [],\n",
       " ['desert'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['trees'],\n",
       " [],\n",
       " ['sunset'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['sea'],\n",
       " ['mountain'],\n",
       " [],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " ['sea'],\n",
       " ['mountain'],\n",
       " ['sunset'],\n",
       " ['mountain'],\n",
       " ['sea'],\n",
       " ['sunset'],\n",
       " [],\n",
       " [],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['trees'],\n",
       " ['sea'],\n",
       " ['sea'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " [],\n",
       " [],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " ['mountain'],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " [],\n",
       " [],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " [],\n",
       " ['sea'],\n",
       " ['sunset'],\n",
       " ['mountain', 'trees'],\n",
       " ['sea'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " [],\n",
       " ['sea', 'sunset'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['mountain'],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " [],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " ['trees'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " ['trees'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['sea', 'sunset'],\n",
       " [],\n",
       " [],\n",
       " ['sea'],\n",
       " ['trees'],\n",
       " ['sea'],\n",
       " ['sunset'],\n",
       " ['sea'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " [],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['sunset'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['mountain'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['desert'],\n",
       " [],\n",
       " [],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['mountain'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['sunset'],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " ['sea'],\n",
       " ['desert'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['trees'],\n",
       " ['sea'],\n",
       " ['sea'],\n",
       " ['mountain'],\n",
       " ['sunset'],\n",
       " [],\n",
       " ['sunset'],\n",
       " ['desert'],\n",
       " [],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " ['desert'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " ['sunset'],\n",
       " ['sea'],\n",
       " ['desert'],\n",
       " ['trees'],\n",
       " ['trees'],\n",
       " ['mountain'],\n",
       " ['sunset'],\n",
       " ['mountain'],\n",
       " ['mountain'],\n",
       " ['desert'],\n",
       " ['sea'],\n",
       " ['sea']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(x_test, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(model.predict(x_test), columns=CLASSES)\n",
    "df_true = pd.DataFrame(y_test, columns=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_acc = (df_test - df_true).abs().sum() / len(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desert22_mountain24_sea29_sunset16_trees22'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = '_'.join([''.join((label, str(int(acc*100)))) for (label, acc) in zip(label_acc.index, label_acc.values)])\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_FILEPATH: /Users/hobs/code/Multitask_Learning_Keras/data/model_desert22_mountain24_sea29_sunset16_trees22.h5\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILEPATH = os.path.join(DATA_DIR, f\"model_{name}.h5\")\n",
    "print(f\"MODEL_FILEPATH: {MODEL_FILEPATH}\")\n",
    "model.save(MODEL_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
